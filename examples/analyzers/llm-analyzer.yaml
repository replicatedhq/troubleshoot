apiVersion: troubleshoot.sh/v1beta2
kind: SupportBundle
metadata:
  name: llm-analyzer-example
spec:
  collectors:
    # Standard collectors
    - clusterInfo: {}
    - clusterResources: {}
    
    # Collect pod logs
    - logs:
        name: pod-logs
        namespace: ""
        limits:
          maxLines: 10000
    
    # Collect events
    - events:
        name: cluster-events
        namespace: ""
  
  analyzers:
    # LLM Analyzer - Uses AI to analyze logs and identify issues
    - llm:
        checkName: "AI-Powered Problem Analysis"
        collectorName: "pod-logs"
        fileName: "*"  # Analyze all files in the collector
        model: "gpt-4o-mini"  # Cost-effective model with 128K context
        maxFiles: 10  # Limit files to prevent token overflow
        maxSize: 1000  # Limit total size to 1MB
        # Smart file selection (optional)
        priorityPatterns: ["error", "fatal", "exception", "OOM", "crash", "panic"]
        skipPatterns: ["*.png", "*.jpg", "debug-*", "*.gz"]
        preferRecent: true  # Analyze newer files first
        useStructuredOutput: true  # Use OpenAI's structured outputs for guaranteed JSON (default: true)
        # Advanced configuration (optional)
        # problemDescription: "Custom problem description"  # Override CLI/env problem description
        # apiEndpoint: "https://api.openai.com/v1/chat/completions"  # Custom endpoint for proxies/testing
        outcomes:
          - fail:
              when: "issue_found"
              message: "Critical issue detected: {{.Summary}}"
          - warn:
              when: "potential_issue"
              message: "Warning: {{.Summary}}"
          - pass:
              message: "No issues detected by AI analysis"
    
    # Traditional analyzers can work alongside LLM
    - clusterVersion:
        outcomes:
          - fail:
              when: "< 1.20.0"
              message: "Kubernetes version is too old"
          - warn:
              when: "< 1.25.0"
              message: "Consider upgrading Kubernetes"
          - pass:
              message: "Kubernetes version is supported"
    
    - deploymentStatus:
        name: default
        namespace: default
        outcomes:
          - fail:
              when: "< 1"
              message: "No replicas are running"
          - warn:
              when: "< 2"
              message: "Only one replica is running"
          - pass:
              message: "Deployment is healthy"

---
# Analyzer-only spec for re-analyzing existing bundles
apiVersion: troubleshoot.sh/v1beta2
kind: Analyzer
metadata:
  name: llm-reanalyzer
spec:
  analyzers:
    - llm:
        checkName: "Re-analysis with AI"
        collectorName: "pod-logs"
        fileName: "*.log"
        model: "gpt-5"  # Override default (gpt-4o-mini) for complex issues
        maxFiles: 30  # Override default (20) for more files
        outcomes:
          - fail:
              when: "issue_found"
              message: |
                AI Analysis Results:
                {{.Summary}}
                
                Root Cause: {{.RootCause}}
                Issue: {{.Issue}}
                Solution: {{.Solution}}
                
                Affected Pods: {{.AffectedPods}}
                Next Steps: {{.NextSteps}}
                Commands: {{.Commands}}
          - pass:
              message: "AI analysis found no significant issues"